+++
draft = false
+++

# Publications

## 2024

<sub>[28] [IllusionVQA: A Challenging Optical Illusion Dataset for Vision Language Models](https://arxiv.org/abs/2403.15952)  
    Haz Sameen Shahgir, Khondker Salman Sayeed, Abhik Bhattacharjee, Wasi Uddin Ahmad, __Yue Dong__, Rifat Shahriyar  
    *Conference on Language Modeling (COLM) 2024*</sub>

<sub>[27] [Cross-task defense: Instruction-tuning LLMs for content safety](https://arxiv.org/abs/2312.06924)  
    Yu Fu, Wen Xiao, Jia Chen, Jiachen Li, Evangelos Papalexakis, Aichi Chien, __Yue Dong__  
    *TrustNLP Workshop @ NAACL 2024*</sub>

<sub>[26] [Safety Alignment in NLP Tasks: Weakly Aligned Summarization as an In-Context Attack](https://arxiv.org/abs/2312.06924)  
    Yu Fu, Yufei Li, Wen Xiao, Cong Liu, __Yue Dong__  
    *ACL 2024*</sub>

<sub>[25] [Asymmetric Bias in Text-to-Image Generation with Adversarial Attacks](https://arxiv.org/abs/2312.14440)  
    Haz Sameen Shahgir, Xianghao Kong, Greg Ver Steeg, __Yue Dong__  
    *ACL Findings 2024*</sub>

<sub>[24] [Subtle Misogyny Detection and Mitigation: An Expert-Annotated Dataset](https://arxiv.org/abs/2311.09443)  
    Brooklyn Sheppard, Anna Richter, Allison Cohen, Elizabeth Allyn Smith, Tamara Kneese, Carolyne Pelletier, Ioana Baldini, __Yue Dong__  
    *ACL Findings 2024*</sub>

<sub>[23] [Source-Free Domain Adaptation for Question Answering with Masked Self-training](https://arxiv.org/abs/2212.09563)  
    Maxwell Yin, Boyu Wang, __Yue Dong__, Charles Ling  
    *TACL 2024*</sub>

<sub>[22] [PAT-Questions: A Self-Updating Benchmark for Present-Anchored Temporal Question-Answering](https://arxiv.org/abs/2402.11034)  
    Jannat Ara Meem, Muhammad Shihab Rashid, __Yue Dong__, Vagelis Hristidis  
    *ACL Findings 2024*</sub>

<sub>[21] [EcoRank: Budget-Constrained Text Re-ranking Using Large Language Models](https://arxiv.org/abs/2402.10866)  
    Muhammad Shihab Rashid, Jannat Ara Meem, __Yue Dong__, Vagelis Hristidis  
    *ACL Findings 2024*</sub>

<sub>[20] [Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models](https://arxiv.org/abs/2401.12345)  
    Erfan Shayegani, __Yue Dong__, Nael Abu-Ghazaleh  
    *ICLR 2024*</sub>

<sub>[19] [Watermarking conditional text generation for AI detection: Unveiling challenges and a semantic-aware watermark remedy](https://arxiv.org/abs/2401.67890)  
    Yu Fu, Deyi Xiong, __Yue Dong__  
    *AAAI 2024*</sub>

### Pre-prints

<sub>- [TRAWL: Tensor Reduced and Approximated Weights for Large Language Models](https://arxiv.org/abs/2406.17261)  
    Y Luo, H Patel, Y Fu, D Ahn, J Chen, __Yue Dong__, EE Papalexakis  
    *arXiv preprint arXiv:2406.17261*</sub>

<sub>- [Progressive Query Expansion for Retrieval Over Cost-constrained Data Sources](https://arxiv.org/abs/2406.07136)  
    MS Rashid, JA Meem, __Yue Dong__, V Hristidis  
    *arXiv preprint arXiv:2406.07136*</sub>

<sub>- [PyramidKV: Dynamic KV Cache Compression based on Pyramidal Information Funneling](https://arxiv.org/abs/2406.02069)  
    Y Zhang, B Gao, T Liu, K Lu, W Xiong, __Yue Dong__, B Chang, J Hu, W Xiao  
    *arXiv preprint arXiv:2406.02069*</sub>

<sub>- [Cross-Modal Safety Alignment: Is textual unlearning all you need?](https://arxiv.org/abs/2406.02575)  
    T Chakraborty, E Shayegani, Z Cai, N Abu-Ghazaleh, MS Asif, __Yue Dong__  
    *arXiv preprint arXiv:2406.02575*</sub>

<sub>- [Uncertainty Awareness of Large Language Models Under Code Distribution Shifts: A Benchmark Study](https://arxiv.org/abs/2402.05939)  
    Y Li, S Chen, Y Guo, W Yang, __Yue Dong__, C Liu  
    *arXiv preprint arXiv:2402.05939*</sub>

<sub>- [BiRNA-BERT Allows Efficient RNA Language Modeling with Adaptive Tokenization](https://biorxiv.org/content/early/2024/07/02/601703)  
    MT Tahmid, HS Shahgir, S Mahbub, __Yue Dong__, MS Bayzid  
    *bioRxiv*</sub>

<sub>- [Mechanisms of non-factual hallucinations in language models](https://arxiv.org/abs/2403.18167)  
    L Yu, M Cao, JCK Cheung, __Yue Dong__  
    *arXiv preprint arXiv:2403.18167*</sub>

### 2023
[18] Survey of vulnerabilities in large language models revealed by adversarial attacks
[17] Inverse Reinforcement Learning for Text Summarization


### 2022
[16] Learning with Rejection for Abstractive Text Summarization
[15] Hallucinated but factual! inspecting the factuality of hallucinations in abstractive summarization
[14] Faithful to the document or to the world? mitigating hallucinations via entity-linked knowledge in abstractive summarization

### 2021
[13] On-the-fly attention modulation for neural generation
[12] Bringing structure into summaries: a faceted summarization dataset for long scientific documents
[11] Discourse-Aware Unsupervised Summarization of Long Scientific Documents


### 2020

[10] Factual error correction for abstractive summarization models
[9]  Multi-XScience: A large-scale dataset for extreme multi-document summarization of scientific articles
[8] Multi-fact correction in abstractive text summarization

### 2019 
[7] Countering the Effects of Lead Bias in News Summarization via Multi-Stage Training and Auxiliary Losses
[6] Learning multi-task communication with message passing for sequence learning
[5] EditNTS: An Neural Programmer-Interpreter Model for Sentence Simplification through Explicit Editing

### Before 2018 
[4]  Banditsum: Extractive summarization as a contextual bandit
[3] Threaded ensembles of autoencoders for stream learning
[2] A hierarchical neural attention-based text classifier
[1] Threaded ensembles of supervised and unsupervised neural networks for stream learning
 
