+++
draft = false
+++

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Publications</title>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        .publication {
            font-size: 0.9em;
        }
        .title {
            font-weight: bold;
        }
        .authors {
            margin-left: 20px;
        }
        .venue {
            margin-left: 20px;
            font-style: italic;
        }
    </style>
</head>
<body>
    <h1>Publications</h1>

    <div class="publication">
        <p class="title">[28] <a href="https://arxiv.org/abs/2403.15952">IllusionVQA: A Challenging Optical Illusion Dataset for Vision Language Models</a></p>
        <p class="authors">Haz Sameen Shahgir, Khondker Salman Sayeed, Abhik Bhattacharjee, Wasi Uddin Ahmad, <u>Yue Dong</u>, Rifat Shahriyar</p>
        <p class="venue">Conference on Language Modeling (COLM) 2024</p>
    </div>

    <div class="publication">
        <p class="title">[27] <a href="https://arxiv.org/abs/2312.06924">Cross-task defense: Instruction-tuning LLMs for content safety</a></p>
        <p class="authors">Yu Fu, Wen Xiao, Jia Chen, Jiachen Li, Evangelos Papalexakis, Aichi Chien, <u>Yue Dong</u></p>
        <p class="venue">TrustNLP Workshop @ NAACL 2024</p>
    </div>

    <div class="publication">
        <p class="title">[26] <a href="https://arxiv.org/abs/2312.06924">Safety Alignment in NLP Tasks: Weakly Aligned Summarization as an In-Context Attack</a></p>
        <p class="authors">Yu Fu, Yufei Li, Wen Xiao, Cong Liu, <u>Yue Dong</u></p>
        <p class="venue">ACL 2024</p>
    </div>

    <div class="publication">
        <p class="title">[25] <a href="https://arxiv.org/abs/2312.14440">Asymmetric Bias in Text-to-Image Generation with Adversarial Attacks</a></p>
        <p class="authors">Haz Sameen Shahgir, Xianghao Kong, Greg Ver Steeg, <u>Yue Dong</u></p>
        <p class="venue">ACL Findings 2024</p>
    </div>

    <div class="publication">
        <p class="title">[24] <a href="https://arxiv.org/abs/2311.09443">Subtle Misogyny Detection and Mitigation: An Expert-Annotated Dataset</a></p>
        <p class="authors">Brooklyn Sheppard, Anna Richter, Allison Cohen, Elizabeth Allyn Smith, Tamara Kneese, Carolyne Pelletier, Ioana Baldini, <u>Yue Dong</u></p>
        <p class="venue">ACL Findings 2024</p>
    </div>

    <div class="publication">
        <p class="title">[23] <a href="https://arxiv.org/abs/2212.09563">Source-Free Domain Adaptation for Question Answering with Masked Self-training</a></p>
        <p class="authors">Maxwell Yin, Boyu Wang, <u>Yue Dong</u>, Charles Ling</p>
        <p class="venue">TACL 2024</p>
    </div>

    <div class="publication">
        <p class="title">[22] <a href="https://arxiv.org/abs/2402.11034">PAT-Questions: A Self-Updating Benchmark for Present-Anchored Temporal Question-Answering</a></p>
        <p class="authors">Jannat Ara Meem, Muhammad Shihab Rashid, <u>Yue Dong</u>, Vagelis Hristidis</p>
        <p class="venue">ACL Findings 2024</p>
    </div>

    <div class="publication">
        <p class="title">[21] <a href="https://arxiv.org/abs/2402.10866">EcoRank: Budget-Constrained Text Re-ranking Using Large Language Models</a></p>
        <p class="authors">Muhammad Shihab Rashid, Jannat Ara Meem, <u>Yue Dong</u>, Vagelis Hristidis</p>
        <p class="venue">ACL Findings 2024</p>
    </div>

    <div class="publication">
        <p class="title">[20] <a href="https://arxiv.org/abs/2401.12345">Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models</a></p>
        <p class="authors">Erfan Shayegani, <u>Yue Dong</u>, Nael Abu-Ghazaleh</p>
        <p class="venue">ICLR 2024</p>
    </div>

    <div class="publication">
        <p class="title">[19] <a href="https://arxiv.org/abs/2401.67890">Watermarking conditional text generation for AI detection: Unveiling challenges and a semantic-aware watermark remedy</a></p>
        <p class="authors">Yu Fu, Deyi Xiong, <u>Yue Dong</u></p>
        <p class="venue">AAAI 2024</p>
    </div>

    <h2>Pre-prints</h2>
    
- [TRAWL: Tensor Reduced and Approximated Weights for Large Language Models](https://arxiv.org/abs/2406.17261)  
    Y Luo, H Patel, Y Fu, D Ahn, J Chen, __Yue Dong__, EE Papalexakis  
    *arXiv preprint arXiv:2406.17261*  

- [Progressive Query Expansion for Retrieval Over Cost-constrained Data Sources](https://arxiv.org/abs/2406.07136)  
    MS Rashid, JA Meem, __Yue Dong__, V Hristidis  
    *arXiv preprint arXiv:2406.07136*  

- [PyramidKV: Dynamic KV Cache Compression based on Pyramidal Information Funneling](https://arxiv.org/abs/2406.02069)  
    Y Zhang, B Gao, T Liu, K Lu, W Xiong, __Yue Dong__, B Chang, J Hu, W Xiao  
    *arXiv preprint arXiv:2406.02069*  

- [Cross-Modal Safety Alignment: Is textual unlearning all you need?](https://arxiv.org/abs/2406.02575)  
    T Chakraborty, E Shayegani, Z Cai, N Abu-Ghazaleh, MS Asif, __Yue Dong__  
    *arXiv preprint arXiv:2406.02575*  

- [Uncertainty Awareness of Large Language Models Under Code Distribution Shifts: A Benchmark Study](https://arxiv.org/abs/2402.05939)  
    Y Li, S Chen, Y Guo, W Yang, __Yue Dong__, C Liu  
    *arXiv preprint arXiv:2402.05939*  


- [BiRNA-BERT Allows Efficient RNA Language Modeling with Adaptive Tokenization](https://biorxiv.org/content/early/2024/07/02/601703)  
    MT Tahmid, HS Shahgir, S Mahbub, __Yue Dong__, MS Bayzid  
    *bioRxiv* 
    
- [Mechanisms of non-factual hallucinations in language models](https://arxiv.org/abs/2403.18167)  
    L Yu, M Cao, JCK Cheung, __Yue Dong__  
 *arXiv preprint arXiv:2403.18167*  

### 2023
[18] Survey of vulnerabilities in large language models revealed by adversarial attacks
[17] Inverse Reinforcement Learning for Text Summarization


### 2022
[16] Learning with Rejection for Abstractive Text Summarization
[15] Hallucinated but factual! inspecting the factuality of hallucinations in abstractive summarization
[14] Faithful to the document or to the world? mitigating hallucinations via entity-linked knowledge in abstractive summarization

### 2021
[13] On-the-fly attention modulation for neural generation
[12] Bringing structure into summaries: a faceted summarization dataset for long scientific documents
[11] Discourse-Aware Unsupervised Summarization of Long Scientific Documents


### 2020

[10] Factual error correction for abstractive summarization models
[9]  Multi-XScience: A large-scale dataset for extreme multi-document summarization of scientific articles
[8] Multi-fact correction in abstractive text summarization

### 2019 
[7] Countering the Effects of Lead Bias in News Summarization via Multi-Stage Training and Auxiliary Losses
[6] Learning multi-task communication with message passing for sequence learning
[5] EditNTS: An Neural Programmer-Interpreter Model for Sentence Simplification through Explicit Editing

### Before 2018 
[4]  Banditsum: Extractive summarization as a contextual bandit
[3] Threaded ensembles of autoencoders for stream learning
[2] A hierarchical neural attention-based text classifier
[1] Threaded ensembles of supervised and unsupervised neural networks for stream learning
 
