+++
draft = false
+++

## 2024

### Peer-reviewed

# Publications

## 2024

### Peer-reviewed

[28] [IllusionVQA: A Challenging Optical Illusion Dataset for Vision Language Models](https://arxiv.org/abs/2403.15952)  
    Haz Sameen Shahgir, Khondker Salman Sayeed, Abhik Bhattacharjee, Wasi Uddin Ahmad, __Yue Dong__, Rifat Shahriyar  
    *Conference on Language Modeling (COLM) 2024*

[27] [Cross-task defense: Instruction-tuning LLMs for content safety](https://arxiv.org/abs/2312.06924)
    Yu Fu, Wen Xiao, Jia Chen, Jiachen Li, Evangelos Papalexakis, Aichi Chien, __Yue Dong__  
    *TrustNLP Workshop @ NAACL 2024*

[26] [Safety Alignment in NLP Tasks: Weakly Aligned Summarization as an In-Context Attack](https://arxiv.org/abs/2312.06924)  
    Yu Fu, Yufei Li, Wen Xiao, Cong Liu, __Yue Dong__  
    *ACL 2024*

[25] [Asymmetric Bias in Text-to-Image Generation with Adversarial Attacks](https://arxiv.org/abs/2312.14440)  
    Haz Sameen Shahgir, Xianghao Kong, Greg Ver Steeg, __Yue Dong__  
    *ACL Findings 2024*

[24] [Subtle Misogyny Detection and Mitigation: An Expert-Annotated Dataset](https://arxiv.org/abs/2311.09443)  
    Brooklyn Sheppard, Anna Richter, Allison Cohen, Elizabeth Allyn Smith, Tamara Kneese, Carolyne Pelletier, Ioana Baldini, __Yue Dong__  
    *ACL Findings 2024*

[23] [Source-Free Domain Adaptation for Question Answering with Masked Self-training](https://arxiv.org/abs/2212.09563)  
    Maxwell Yin, Boyu Wang, __Yue Dong__, Charles Ling  
    *TACL 2024*

[22] [PAT-Questions: A Self-Updating Benchmark for Present-Anchored Temporal Question-Answering](https://arxiv.org/abs/2402.11034)  
    Jannat Ara Meem, Muhammad Shihab Rashid, __Yue Dong__, Vagelis Hristidis  
    *ACL Findings 2024*

[21] [EcoRank: Budget-Constrained Text Re-ranking Using Large Language Models](https://arxiv.org/abs/2402.10866)  
    Muhammad Shihab Rashid, Jannat Ara Meem, __Yue Dong__, Vagelis Hristidis  
    *ACL Findings 2024*

[20] Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models  
    Erfan Shayegani, __Yue Dong__, Nael Abu-Ghazaleh  
    *ICLR 2024*

[19] Watermarking conditional text generation for AI detection: Unveiling challenges and a semantic-aware watermark remedy  
    Yu Fu, Deyi Xiong, __Yue Dong__  
    *AAAI 2024*
    
### Pre-prints

- TRAWL: Tensor Reduced and Approximated Weights for Large Language Models
- Progressive Query Expansion for Retrieval Over Cost-constrained Data Sources
- PyramidKV: Dynamic KV Cache Compression based on Pyramidal Information Funneling 
- Cross-Modal Safety Alignment: Is textual unlearning all you need?
- Uncertainty Awareness of Large Language Models Under Code Distribution Shifts: A Benchmark Study
- BiRNA-BERT Allows Efficient RNA Language Modeling with Adaptive Tokenization
-  Mechanisms of non-factual hallucinations in language models


### 2023
[18] Survey of vulnerabilities in large language models revealed by adversarial attacks
[17] Inverse Reinforcement Learning for Text Summarization


### 2022
[16] Learning with Rejection for Abstractive Text Summarization
[15] Hallucinated but factual! inspecting the factuality of hallucinations in abstractive summarization
[14] Faithful to the document or to the world? mitigating hallucinations via entity-linked knowledge in abstractive summarization

### 2021
[13] On-the-fly attention modulation for neural generation
[12] Bringing structure into summaries: a faceted summarization dataset for long scientific documents
[11] Discourse-Aware Unsupervised Summarization of Long Scientific Documents


### 2020

[10] Factual error correction for abstractive summarization models
[9]  Multi-XScience: A large-scale dataset for extreme multi-document summarization of scientific articles
[8] Multi-fact correction in abstractive text summarization

### 2019 
[7] Countering the Effects of Lead Bias in News Summarization via Multi-Stage Training and Auxiliary Losses
[6] Learning multi-task communication with message passing for sequence learning
[5] EditNTS: An Neural Programmer-Interpreter Model for Sentence Simplification through Explicit Editing

### Before 2018 
[4]  Banditsum: Extractive summarization as a contextual bandit
[3] Threaded ensembles of autoencoders for stream learning
[2] A hierarchical neural attention-based text classifier
[1] Threaded ensembles of supervised and unsupervised neural networks for stream learning
 
